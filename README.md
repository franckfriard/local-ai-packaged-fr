# üì¶ Package IA Auto-h√©berg√© (Self-hosted AI Starter Kit)

> **Note :** Ceci est une version fran√ßaise du projet original [local-ai-packaged](https://github.com/coleam00/local-ai-packaged) de Cole. Il s'agit d'un environnement complet pour d√©ployer des agents IA en local ou sur serveur.

Ce mod√®le Docker Compose permet de lancer rapidement un environnement de d√©veloppement **IA & Low-Code** enti√®rement fonctionnel et s√©curis√©. Il combine :
* **Ollama** pour ex√©cuter vos mod√®les de langage (LLM) en local.
* **n8n** pour cr√©er des workflows et des agents autonomes.
* **Open WebUI** pour une interface de chat (type ChatGPT) connect√©e √† vos agents.
* **Supabase** pour la base de donn√©es (Postgres), le stockage vectoriel et l'authentification.

Cette version am√©lior√©e inclut √©galement **Flowise**, **Neo4j**, **Langfuse**, **SearXNG** et **Caddy** ! Des workflows d'agents RAG pr√©-construits sont inclus dans le dossier `n8n/backup/workflows/`.

‚ö†Ô∏è **IMPORTANT :** Si vous mettez √† jour une installation existante (avant le 14 juin), vous devez ajouter `POOLER_DB_POOL_SIZE=5` dans votre fichier `.env`.

---

## üîó Liens Utiles
* [Forum de la communaut√© Local AI](https://forum.ottomator.ai/) (oTTomator Think Tank)
* [Tableau de bord du projet](https://github.com/users/coleam00/projects/3) (Roadmap & Bugs)
* [Kit de d√©marrage original n8n](https://github.com/n8n-io/self-hosted-ai-starter-kit)

---

## üõ†Ô∏è Ce qui est inclus dans la stack

* ‚úÖ **n8n (Self-hosted)** : Plateforme d'automatisation Low-code avec +400 int√©grations.
* ‚úÖ **Supabase** : Alternative Open Source √† Firebase. La base de donn√©es de r√©f√©rence pour les agents IA.
* ‚úÖ **Ollama** : Pour faire tourner les derniers mod√®les LLM (Llama 3, Mistral, etc.) en local.
* ‚úÖ **Open WebUI** : Interface utilisateur riche pour interagir avec vos mod√®les et agents n8n.
* ‚úÖ **Flowise** : Constructeur d'agents IA en mode "Drag & Drop".
* ‚úÖ **Qdrant** : Base de donn√©es vectorielle haute performance (conserv√©e en plus de Supabase pour sa rapidit√© sp√©cifique sur le RAG).
* ‚úÖ **Neo4j** : Moteur de graphe de connaissances (Knowledge Graph) pour le GraphRAG.
* ‚úÖ **SearXNG** : Moteur de m√©ta-recherche respectueux de la vie priv√©e (agr√®ge Google, Bing, etc. sans tra√ßage).
* ‚úÖ **Caddy** : Serveur Web automatique pour g√©rer le HTTPS et vos noms de domaine.
* ‚úÖ **Langfuse** : Outil d'observabilit√© pour monitorer et d√©bugger vos agents LLM.

---

## üìã Pr√©requis

Avant de commencer, assurez-vous d'avoir install√© :
* **Python** (Requis pour le script de d√©marrage)
* **Git** (Pour cloner le projet)
* **Docker & Docker Desktop** (Indispensable pour faire tourner les conteneurs)

---

## üöÄ Installation

### 1. Cloner le d√©p√¥t
```bash
git clone [https://github.com/franckfriard/local-ai-packaged-fr.git](https://github.com/franckfriard/local-ai-packaged-fr.git)
cd local-ai-packaged-fr

```

### 2. Configuration des variables d'environnement

Faites une copie du fichier d'exemple et renommez-le :

```bash
cp .env.example .env

```

Ouvrez le fichier `.env` et remplissez les variables de s√©curit√© (g√©n√©rez des mots de passe forts pour la production !) :

```ini
############# Configuration N8N ############
N8N_ENCRYPTION_KEY=votre_cl√©_magique
N8N_USER_MANAGEMENT_JWT_SECRET=votre_secret_jwt

############# Secrets Supabase ############
POSTGRES_PASSWORD=votre_mot_de_passe_db
JWT_SECRET=votre_secret_jwt_supabase
ANON_KEY=votre_cl√©_anon
SERVICE_ROLE_KEY=votre_cl√©_service
DASHBOARD_USERNAME=admin
DASHBOARD_PASSWORD=votre_mot_de_passe_admin
POOLER_TENANT_ID=votre_tenant_id

############# Secrets Neo4j ############
NEO4J_AUTH=neo4j/votre_mot_de_passe

############# Identifiants Langfuse ############
CLICKHOUSE_PASSWORD=votre_mdp
MINIO_ROOT_PASSWORD=votre_mdp
LANGFUSE_SALT=votre_salt
NEXTAUTH_SECRET=votre_secret
ENCRYPTION_KEY=votre_cl√©

```

### 3. D√©marrage des services

Le script `start_services.py` facilite le lancement selon votre mat√©riel.

**Pour les utilisateurs Nvidia GPU :**

```bash
python start_services.py --profile gpu-nvidia

```

**Pour les utilisateurs Mac / Apple Silicon (M1/M2/M3) :**
Docker sur Mac ne peut pas acc√©der au GPU directement.

* **Option Recommand√©e :** Installez [Ollama pour Mac](https://ollama.com/download) directement sur votre machine (hors Docker) pour la vitesse, puis lancez le reste de la stack :
```bash
python start_services.py --profile none

```


*(Note : Dans ce cas, configurez `OLLAMA_HOST=host.docker.internal:11434` dans le `docker-compose.yml` section n8n)*.
* **Option Tout CPU (Lent) :**
```bash
python start_services.py --profile cpu

```



---

## üåê Environnement (Priv√© vs Public)

Le script accepte un argument `--environment` :

* `private` (par d√©faut) : Id√©al pour le **local**. De nombreux ports sont ouverts pour faciliter le d√©veloppement.
* `public` : Id√©al pour un **VPS/Cloud**. Seuls les ports 80 et 443 sont ouverts via Caddy pour une s√©curit√© maximale.

Exemple pour un d√©ploiement serveur s√©curis√© :

```bash
python3 start_services.py --profile gpu-nvidia --environment public

```

---

## ‚ö°Ô∏è D√©marrage Rapide & Utilisation

Une fois les services lanc√©s :

1. **Acc√©dez √† n8n :** Ouvrez `http://localhost:5678`. Cr√©ez votre compte admin local.
2. **Importez les Workflows :**
* Dans n8n, allez dans "Workflows" > "Import from File".
* S√©lectionnez les fichiers JSON situ√©s dans le dossier `n8n/backup/workflows/` de ce projet.


3. **Configurez les Credentials dans n8n :**
* **Ollama :** URL = `http://ollama:11434`
* **Postgres (Supabase) :** Host = `db`, User/Pass = ceux de votre `.env`.
* **Qdrant :** URL = `http://qdrant:6333`


4. **Acc√©dez √† Open WebUI :** Ouvrez `http://localhost:3000`.
* Cr√©ez un compte (local uniquement).
* Pour connecter n8n : Allez dans `Workspace` > `Functions` > `Add Function`.
* Collez le code du fichier `n8n_pipe.py`.
* Activez la fonction et collez l'URL du Webhook de Production de votre workflow n8n.



---

## üîß D√©pannage (Troubleshooting)

* **Supabase Pooler red√©marre en boucle :** Voir cette [issue GitHub](https://github.com/supabase/supabase/issues).
* **Erreur de connexion Database :** Assurez-vous que votre mot de passe Postgres **ne contient pas** le caract√®re `@`.
* **Probl√®me GPU Windows :** V√©rifiez que vous utilisez bien le backend **WSL 2** dans Docker Desktop.
* **N≈ìud "Local File Trigger" manquant :** Dans n8n v2+, ce n≈ìud est d√©sactiv√© par s√©curit√©. Pour l'activer, d√©commentez `NODES_EXCLUDE=[]` dans le fichier `docker-compose.yml`.

---

## üìú Licence

Ce projet est sous licence **Apache-2.0**.
Bas√© sur le travail de l'√©quipe n8n et les contributions de la communaut√© Open Source.

```

```
